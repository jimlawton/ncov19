{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import base packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requests is special, becuae it's not part of the Python standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import requests\n",
    "except NameError:\n",
    "    !{sys.executable} -m pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the URLs for th JHU Coronavirus time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_url = 'https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv'\n",
    "deaths_url = 'https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv'\n",
    "recovered_url = 'https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the confirmed cases data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(cases_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response (r) from the website contains, in its 'text' attribute, the raw data.\n",
    "The raw data is in CSV (Comma Separated Value) format, a row per line.\n",
    "Split the raw data into separate lines, giving a list of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_csv = r.text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CSV reader to generate a list of values for each row, so now we have a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_data = [row for row in csv.reader(cases_csv)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(deaths_url)\n",
    "deaths_csv = r.text.splitlines()\n",
    "deaths_data = [row for row in csv.reader(deaths_csv)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the recovered cases data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(recovered_url)\n",
    "recovered_csv = r.text.splitlines()\n",
    "recovered_data = [row for row in csv.reader(recovered_csv)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will contain in its first element (row), the list of heading from the CSV data.\n",
    "Separate the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = cases_data[0]\n",
    "cases_data = cases_data[1:]\n",
    "deaths_data = deaths_data[1:]\n",
    "recovered_data = recovered_data[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check, make sure all data sets are the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(cases_data) == len(deaths_data) == len(recovered_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The header is in this form:\n",
    "`['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20', ... ]`\n",
    "Let's process it a bit to put the dates in ISO format.\n",
    "Make a list of all the date values. We'll need this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "# Skip the first 4 headers, the rest will all be dates.\n",
    "for field in header[4:]:\n",
    "    date = datetime.datetime.strptime(field, '%m/%d/%y')\n",
    "    # This converts '3/23/20' into '2020-03-23T00:00:00'.\n",
    "    # Strip off the last 9 characters, we don't care about the H:M:S.\n",
    "    new_date = str(date.isoformat())[:-9]\n",
    "    dates.append(new_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a dictionary (map), which is easier to refer to and process.\n",
    "We'll key the dictionary by country. So, it will look something like:\n",
    "Province/State is not used, we'll roll up the data by country.\n",
    "\n",
    "```\n",
    "{\n",
    "    'latitude': '15.0',\n",
    "    'longitude': '101.0',\n",
    "    'cases': {\n",
    "        '2020-01-22': '2',\n",
    "        '2020-01-23': '3',\n",
    "        ...\n",
    "    },\n",
    "    'deaths': {\n",
    "        '2020-01-22': '0',\n",
    "        '2020-01-23': '1',\n",
    "        ...\n",
    "    },\n",
    "    'recovered': {\n",
    "        '2020-01-22': '0',\n",
    "        '2020-01-23': '1',\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the heavy lifting. Gather all the data from the CSV tables and put it into the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = {}\n",
    "for i, row in enumerate(cases_data):\n",
    "    # 'i' increments with each row.\n",
    "    # We can use 'i' to find the corresponding row in the deaths and recovered data.\n",
    "    country = row[1]\n",
    "    assert(country != '')    # Country should never be blank.\n",
    "    province = row[0]\n",
    "    if country == 'United Kingdom':\n",
    "        country = province\n",
    "        province = ''\n",
    "    latitude = row[2]\n",
    "    longitude = row[3]\n",
    "    cases_row_data = row[4:]\n",
    "    deaths_row = deaths_data[i]\n",
    "    deaths_row_data = deaths_row[4:]\n",
    "    recovered_row = recovered_data[i]\n",
    "    recovered_row_data = recovered_row[4:]\n",
    "\n",
    "    # These should be the same, just check in case something has gone wrong.\n",
    "    assert(len(cases_row_data) == len(deaths_row_data) == len(recovered_row_data) == len(dates))\n",
    "\n",
    "    if country not in data_map:\n",
    "        # This country is not already in the map. Add it.\n",
    "        data_map[country] = {\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'cases': {},\n",
    "            'deaths': {},\n",
    "            'recovered': {}\n",
    "        }\n",
    "        for d in dates:\n",
    "            data_map[country]['cases'][d] = 0\n",
    "            data_map[country]['deaths'][d] = 0\n",
    "            data_map[country]['recovered'][d] = 0\n",
    "\n",
    "    for j, value in enumerate(cases_row_data):\n",
    "        # 'j' increments with each value in row_data: 0, 1, ...\n",
    "        # We can use 'j' to find the corresponding date in the list of dates.\n",
    "        # This country is already in the map. Add the data to existing data.\n",
    "        if value == '':\n",
    "            intval = 0\n",
    "        else:\n",
    "            intval = int(value)\n",
    "        new_value = int(data_map[country]['cases'][dates[j]]) + intval\n",
    "        data_map[country]['cases'][dates[j]] = f\"{new_value}\"\n",
    "\n",
    "    for j, value in enumerate(deaths_row_data):\n",
    "        if value == '':\n",
    "            intval = 0\n",
    "        else:\n",
    "            intval = int(value)\n",
    "        new_value = int(data_map[country]['deaths'][dates[j]]) + intval\n",
    "        data_map[country]['deaths'][dates[j]] = f\"{new_value}\"\n",
    "\n",
    "    for j, value in enumerate(recovered_row_data):\n",
    "        if value == '':\n",
    "            intval = 0\n",
    "        else:\n",
    "            intval = int(value)\n",
    "        new_value = int(data_map[country]['recovered'][dates[j]]) + intval\n",
    "        data_map[country]['recovered'][dates[j]] = f\"{new_value}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets filter to a smaller set of countries for now. Just Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    \"Albania\", \"Andorra\", \"Austria\", \"Belgium\", \"Bosnia and Herzegovina\",\n",
    "    \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czechia\", \"Denmark\", \"Estonia\", \"Finland\",\n",
    "    \"France\", \"Germany\", \"Gibraltar\", \"Greece\", \"Holy See\", \"Hungary\", \"Iceland\",\n",
    "    \"Ireland\", \"Italy\", \"Kosovo\", \"Latvia\", \"Liechtenstein\", \"Lithuania\",\n",
    "    \"Luxembourg\", \"Malta\", \"Monaco\", \"Montenegro\", \"Netherlands\",\n",
    "    \"North Macedonia\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"San Marino\",\n",
    "    \"Serbia\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\",\n",
    "    \"United Kingdom\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
